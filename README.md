# Decision Match AI â€” Datathon (Machine Learning Engineering)

> **FIAP Datathon â€” IA aplicada a recrutamento e seleÃ§Ã£o**  
> Pipeline completa de ML com deploy em API (FastAPI), empacotamento Docker, testes, logging e documentaÃ§Ã£o.

## ğŸ¯ VisÃ£o Geral

Este projeto endereÃ§a as dores do case **Decision (bodyshop / R&S)** com uma soluÃ§Ã£o de IA para **rankear candidatas(os) por vaga** a partir de dados estruturados (vagas, prospects e applicants), combinando **engenharia de atributos textual (TFâ€‘IDF)** e **similaridade de cosseno** para cÃ¡lculo de afinidade entre **perfil de vaga** e **perfil do candidato**.  
Os **requisitos de entrega** foram definidos pelo PDF do Datathon (**PÃ“S TECH â€“ Datathon MLE**). Veja a matriz de conformidade mais abaixo.

---

## ğŸ§± Arquitetura e Fluxo (Mermaid)

```mermaid
flowchart LR
    A[Dados brutos\napplicants.json, prospects.json, vagas.json] --> B[PrÃ©-processamento\nlimpeza e normalizaÃ§Ã£o]
    B --> C[Feature Engineering\nTFâ€‘IDF: competÃªncias/atividades vs. skills do CV]
    C --> D[Modelo de Matching\nCosine Similarity]
    D --> E[Artefatos\nmodel.joblib, artifacts.joblib]
    E --> F[API FastAPI\n/endpoints de ranking e consulta]
    F --> G[Docker\nImagem e Compose]
    F --> H[Logging & Monitoramento\napp.logging â†’ /logs]
    F --> I[Testes\npytest]
```

---

## ğŸ—‚ï¸ Estrutura (pastas/arquivos principais)

```
app/
  â”œâ”€ main.py              # bootstrap da API FastAPI
  â”œâ”€ routes.py            # endpoints: health, /jobs, /candidates, /rank/{{job_id}}
  â”œâ”€ model/
  â”‚   â”œâ”€ model.joblib     # modelo serializado (joblib)
  â”‚   â””â”€ artifacts.joblib # vetorizador TFâ€‘IDF e metadados
build/
data/                     # applicants.json, prospects.json, vagas.json
logs/                     # saÃ­da de logs estruturados
notebooks/                # EDA e preparaÃ§Ã£o do dataset
src/
tests/                    # testes de API e utilitÃ¡rios (pytest)
dockerfile
docker-compose.yml
requirements.txt
```
Arquivos como **`dockerfile`** e **`docker-compose.yml`** se encontram na raiz do repositÃ³rio pÃºblico. (ver repositÃ³rio no GitHub)

---

## âœ… Matriz de Requisitos (Datathon) â€” *evidÃªncias*

> Requisitos extraÃ­dos do PDF e cruzados com os artefatos do repo/cÃ³digo.

1. **Treinamento do modelo preditivo** (pipeline completa, serializaÃ§Ã£o `joblib`)  
   - **EvidÃªncia**: notebook de EDA/feature engineering e consolidaÃ§Ã£o de dataset; artefatos serializados.  
   - **IndÃ­cios no cÃ³digo**: carregamento de **`model.joblib`** e **`artifacts.joblib`** com o vetorizar **TFâ€‘IDF**:
     ```python
model = joblib.load("app/model/model.joblib")
arts  = joblib.load("app/model/artifacts.joblib")
tfidf = arts["tfidf"]
feat_names = arts["feat_names"]  
MAP_LVL = arts.get("map_lvl", {})
MAP_SENIOR = arts.get("map_senior", {})
skills = set(arts.get("skills_seed", [])) | set(arts.get("skills_mined_sample", []))
     ```
   - **CÃ¡lculo de matching**: uso de **similaridade do cosseno** para ranquear candidatos:
     ```python
cosine_similarity(X_job, X_cv)[0,0])

    vi = _map_level(row.get("nivel_ingles_vaga",""), MAP_LVL)
    ci = _map_level(row.get("applicant_nivel_ingles",""), MAP_LVL)
    ingles_ok = int(ci >= vi)

  
# ... (trecho truncado para o README)
     ```
   - **Notebook**: consolidaÃ§Ã£o de dados de `applicants`, `prospects` e `vagas` (amostra abaixo).  
Notebook com **25 cÃ©lulas**. Primeiro trecho relevante:

```python
import pandas as pd
import json
import matplotlib.pyplot as plt
import seaborn as sns
import re
import string
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import nltk
```

2. **ModularizaÃ§Ã£o do cÃ³digo** (arquitetura limpa em `.py`)  
   - **EvidÃªncia**: `app/main.py` (bootstrap/uvicorn), `app/routes.py` (endpoints), `app/model/` (artefatos), `tests/` (pytest).  
   - **Trecho** (FastAPI + lifespan):
     ```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Gerenciador de ciclo de vida: carrega os dados na inicializaÃ§Ã£o da API.
    """
    print("Iniciando a API e carregando os dados...")
    df_vagas, df_candidatos = load_data()
    dataframes["vagas"] = df_vagas
    dataframes["candidatos"] = df_candidatos
    yield
    # CÃ³digo executado no encerramento
    print("Encerrando a API...")
    dataframes.clear()
# --- 2. InicializaÃ§Ã£o da AplicaÃ§Ã£o FastAPI ---
     ```

3. **API para deployment do modelo** (`/predict` ou endpoint equivalente de ranking)  
   - **EvidÃªncia**: endpoint **`POST /rank/{job_id}`** com `top_n`, alÃ©m de **health**, **jobs** e **candidates**.
     ```python
def register_routes(app, df_vagas, df_candidatos):
     ```
   - **Modelo de resposta**:
     ```python
class CandidateRank(BaseModel):
    id_candidato: int
    nome_candidato: str
    score: float
     ```

4. **Empacotamento em Docker**  
   - **EvidÃªncia**: presenÃ§a de **`dockerfile`** e **`docker-compose.yml`** no repositÃ³rio.

5. **Deploy do modelo (local/Nuvem)**  
   - **EvidÃªncia**: stack com FastAPI + Uvicorn (comandos abaixo) e Compose para subir a API.

6. **Teste da API**  
   - **EvidÃªncia**: suÃ­te **pytest** em `tests/` (ex.: `teste_rotas.py`).  
   - **Trecho** (setup e smoke de rotas):
     ```python
# tests/test_main.py

import pytest
from fastapi.testclient import TestClient
import pandas as pd

# Adiciona o diretÃ³rio 'src' ao caminho para que o Python encontre 'main.py'
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..','app')))
print(str(os.path.abspath(os.path.join(os.path.dirname(__file__)))))
# Importa o app DEPOIS de ajustar o path
from main import app

# --- Fixture de Teste ---
# Esta funÃ§Ã£o prepara um ambiente de teste limpo para cada teste. 
@pytest.fixture
def client_with_mock_data(monkeypatch):
    """
    Esta fixture simula (mocks) a funÃ§Ã£o load_data ANTES que a aplicaÃ§Ã£o inicie.
    """
    mock_vagas_df = pd.DataFrame([
        {'id_vaga': 5185, 'titulo_vaga_detalhado': 'Vaga de Teste 1'}
    ])
    mock_candidatos_df = pd.DataFrame([
        {'id_candidato': 31001, 'applicant_nome': 'Candidato Teste A'}
    ])

    # FunÃ§Ã£o falsa que retorna nossos dados simulados
    def mock_load_data():
        print("--- Usando dados simulados (mock) para o teste ---")
        return mock_vagas_df, mock_candidatos_df

    # Substitui a funÃ§Ã£o real 'load_data' pela nossa versÃ£o simulada
    monkeypatch.setattr("main.load_data", mock_load_data)

    # O TestClient iniciarÃ¡ a aplicaÃ§Ã£o. O 'lifespan' chamarÃ¡ nossa
    # funÃ§Ã£o 'mock_load_data' em vez da original, evitando a leitura de arquivos.
    with TestClient(app) as client:
        yield client


# --- Testes Corrigidos para cada Rota da API ---
# Note que todos os testes agora recebem 'client_with_mock_data' como argumento
     ```

7. **Testes unitÃ¡rios (meta â‰¥80% cobertura)**  
   - **EvidÃªncia**: testes com `pytest`. (A cobertura exata depende da execuÃ§Ã£o em CI; comandos abaixo).

8. **Monitoramento contÃ­nuo (logs + painel de drift)**  
   - **EvidÃªncia**: uso de **`app.logging.log_event(...)`** em rotas, gerando **logs estruturados** em `/logs`.  
     *ObservaÃ§Ã£o:* o painel de **drift** pode ser acoplado (ex.: Prometheus/Grafana/Streamlit) e tem trilha sugerida na seÃ§Ã£o *Roadmap*.

> Fonte dos requisitos do Datathon: ver PDF do desafio incluÃ­do na raiz do projeto.

---

## ğŸš€ Como executar

### 1) Local (sem Docker)
```bash
# 1. Python 3.10+ e virtualenv
python -m venv .venv && source .venv/bin/activate

# 2. DependÃªncias
pip install --upgrade pip
pip install -r requirements.txt

# 3. Executar API (FastAPI + Uvicorn)
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

# 4. Abrir docs
# Swagger UI: http://localhost:8000/docs
# Redoc:      http://localhost:8000/redoc
```

### 2) Docker (simples)
```bash
# Build da imagem
docker build -t decision-match:latest .

# Run da API
docker run --rm -p 8000:8000 decision-match:latest
```

### 3) Docker Compose
```bash
docker compose up --build
```

---

## ğŸ“¡ Endpoints principais

- `GET /` â€” Health Check  
- `GET /jobs/` â€” Lista de vagas  
- `GET /jobs/{job_id}` â€” Detalhe de vaga  
- `POST /jobs/` â€” Cria vaga (payload mÃ­nimo)  
- `GET /candidates/?skip=0&limit=20` â€” PaginaÃ§Ã£o de candidatas(os)  
- `POST /rank/{job_id}?top_n=5` â€” **Ranking de candidatas(os)** para a vaga

### Exemplo de chamada (cURL)
```bash
curl -X POST "http://localhost:8000/rank/123?top_n=5" -H "Content-Type: application/json" -d "{}"
```

Resposta (exemplo):
```json
{
  "ranking": [
    { "id_candidato": 987, "nome_candidato": "Ana", "score": 0.84 },
    { "id_candidato": 654, "nome_candidato": "Bruno", "score": 0.81 }
  ]
}
```

---

## ğŸ”¬ Como o modelo funciona (resumo tÃ©cnico)

- **Entrada de features textuais**: campos de descriÃ§Ã£o/competÃªncias da vaga vs. histÃ³rico/skills do candidato.  
- **VetorizaÃ§Ã£o**: **TFâ€‘IDF** (artefato persistido em `artifacts.joblib`).  
- **Matching**: **cosine similarity** entre vetor da vaga e vetores de CVs â†’ **ranking**.  
- **SerializaÃ§Ã£o**: `joblib` para `model.joblib` e `artifacts.joblib`.  
- **ServiÃ§o**: FastAPI entrega `/rank/{{job_id}}` com payload Pydantic tipado.

---

## ğŸ§ª Testes

```bash
# Executar testes
pytest -q

# Cobertura (exemplo)
pytest --cov=app --cov-report=term-missing -q
```

---

## ğŸ“ˆ Monitoramento (logs) e Drift

- **Logs estruturados** com `log_event(...)` para cada rota (sucesso/erro/latÃªncia).  
- **SugestÃ£o de painel de drift**: coletar distribuiÃ§Ã£o de `scores` por vaga ao longo do tempo; comparar com janela de baseline (ex.: KS test) e alertar no dashboard (Grafana/Streamlit).

---

## ğŸ—ºï¸ Roadmap (evoluÃ§Ãµes sugeridas)

- **Melhorar avaliaÃ§Ã£o offline** com mÃ©tricas de ranking (ex.: NDCG@K, MAP@K).  
- **Feedback loop** das(os) hunters/gestores para *reinforcement* com reordenaÃ§Ã£o de ranking.  
- **Features** comportamentais (tempo de resposta, engajamento) para enriquecer o matching.  
- **Painel de drift** e alarmes (Prometheus/Grafana).

---

## ğŸ“š Stack

**Python 3.x**, **FastAPI**, **Pydantic**, **scikitâ€‘learn**, **pandas**, **numpy**, **joblib**, **Uvicorn**, **pytest**, **Docker**.

---

## ğŸ‘¥ CrÃ©ditos

Projeto acadÃªmico para o **Datathon (PÃ“S TECH / FIAP)**. Agradecimentos ao time e Ã  banca avaliadora.
